# -- Target namespace for all resources
namespace: kvcache-manager

# -- PYTHONHASHSEED for deterministic hashing, must match between vLLM and kv-cache-manager.
# This is only used when kvCacheManager.enabled is true.
pythonHashSeed: "0"

# -- VLLM Deployment Configuration
vllm:
  # -- Number of VLLM replicas
  replicaCount: 4
  # -- Inference pool label key
  poolLabelKey: app
  # -- Inference pool label value
  poolLabelValue: vllm-llama-70b

  image:
    # -- VLLM image repository
    repository: vllm/vllm-openai
    # -- VLLM image tag (overrides Chart.yaml appVersion if set)
    tag: "v0.10.0"
    # -- VLLM image pull policy
    pullPolicy: IfNotPresent

  model:
    # -- Hugging Face model name (e.g., mistralai/Mistral-7B-Instruct-v0.2)
    name: meta-llama/Llama-3.1-70B-Instruct
    # -- Label used for Kubernetes resources related to this model instance
    label: vllm-llama-70b
    # -- Maximum model length parameter for VLLM
    maxModelLen: 16384

  # -- Maximum number of batched tokens for VLLM
  maxNumBatchedTokens: 1024

  # -- Enable or disable chunked prefill
  enableChunkedPrefill: true

  # -- GPU memory utilization (optional, e.g., 0.95)
  gpuMemoryUtilization: null
  # -- Tensor parallel size (optional, e.g., 2)
  tensorParallelSize: 4

  # -- VLLM container resource requests and limits
  resources:
    limits:
      nvidia.com/gpu: '4'
    requests:
      cpu: '10'
      memory: 40Gi
      nvidia.com/gpu: '4'

  # -- Node affinity configuration
  affinity: {}

  # -- Liveness probe configuration
  livenessProbe:
    httpGet:
      path: /health
      port: 8000
      scheme: HTTP
    initialDelaySeconds: 15
    timeoutSeconds: 1
    periodSeconds: 10
    successThreshold: 1
    failureThreshold: 3

  # -- Startup probe configuration
  startupProbe:
    httpGet:
      path: /health
      port: 8000
      scheme: HTTP
    initialDelaySeconds: 15
    timeoutSeconds: 1
    periodSeconds: 10
    successThreshold: 1
    failureThreshold: 60 # Higher threshold for startup

  # -- Additional environment variables for VLLM container
  extraEnv:
    VLLM_RPC_TIMEOUT: '1000000'
    # LMCACHE_LOOKUP_URL will be set automatically based on redis service name
    # LMCACHE_DISTRIBUTED_URL will be set automatically based on pod IP

  # -- Block size for prefix-cache block chunking
  blockSize: 64

# -- KV Cache Manager Configuration
kvCacheManager:
  # -- Enable deployment of the kv-cache-manager. It will listen for events from vLLM.
  enabled: true
  # -- Number of kv-cache-manager replicas
  replicaCount: 1
  image:
    # -- kv-cache-manager image repository
    repository: ghcr.io/llm-d/llm-d-kv-cache-manager
    # -- kv-cache-manager image tag
    tag: 0.0.3
    # -- kv-cache-manager image pull policy
    pullPolicy: Always
  # -- ZMQ topic for vLLM to publish to and for the manager to subscribe to
  zmqTopic: "kv@"
  # -- Concurrency for the event processing pool in the manager
  poolConcurrency: "4"
  service:
    # -- Port for the ZMQ service that vLLM connects to
    port: 5557
    # -- HTTP port for the kv-cache-manager service
    httpPort: 8080
  # -- kv-cache-manager container resource requests and limits
  resources:
    requests:
      cpu: "8"
      memory: "1Gi"
    limits:
      cpu: "8"
      memory: "5Gi"

# -- LMCache Connector Configuration
lmcache:
  # -- Enable the LMCache connector for KV cache transfer
  enabled: false
  # -- The name of the KV cache connector to use
  connector: "LMCacheConnectorV1"
  # -- The role of the vLLM instance in the KV cache transfer
  role: "kv_both"
  # -- Use experimental features of LMCache
  useExperimental: true
  # -- Enable local CPU caching
  localCpu: true
  # -- Enable debug logging for LMCache
  enableDebug: true
  # -- Maximum size of the local CPU cache
  maxLocalCpuSize: "40"

  # -- Redis Lookup Server Configuration (used by LMCache)
  redis:
    # -- Enable Redis deployment
    enabled: false
    # -- Redis deployment name suffix
    nameSuffix: lookup-server
    # -- Number of Redis replicas
    replicaCount: 1
    image:
      # -- Redis image repository
      repository: redis
      # -- Redis image tag
      tag: latest
      # -- Redis image pull policy
      pullPolicy: IfNotPresent
    # -- Redis container resource requests and limits
    resources:
      limits:
        # -- Redis CPU limit
        cpu: '8'
        # -- Redis memory limit
        memory: 30G
      requests:
        # -- Redis CPU request
        cpu: '4'
        # -- Redis memory request
        memory: 8G
    service:
      # -- Redis service name suffix
      nameSuffix: lookup-server-service
      # -- Redis service type
      type: ClusterIP
      # -- Port the service exposes
      port: 8100
      # -- Target port on the Redis container
      targetPort: 6379 # Default Redis port

# -- Secret Configuration for Hugging Face Token
secret:
  # -- Name of the Kubernetes secret object
  name: vllm-p2p-secrets
  # -- (Required if create=true) The raw Hugging Face token. Provide via --set or a values file.
  # @ignored ref: https://helm.sh/docs/chart_best_practices/values/#secrets
  hfTokenValue: ""
  # -- Set to true to create the secret. If false, assumes secret 'name' already exists.
  # @default -- false
  create: true
  # -- Key name within the secret (will be formatted like 'hf_token_<model.label>')
  keyPrefix: hf_token

# -- Persistence Configuration using PVC
persistence:
  # -- Enable persistence using a PersistentVolumeClaim
  enabled: true
  # -- PVC name (if not set, it will be templated)
  name: ""
  # -- PVC access mode
  accessModes:
    - ReadWriteMany
  # -- PVC storage size
  size: 50Gi
  # -- Optional: Storage class name for the PVC
  storageClassName: ""
  # -- Mount path inside the VLLM container for Hugging Face cache
  mountPath: /data

# -- Configuration for /dev/shm volume
dshm:
  # -- Use an empty directory for /dev/shm
  useEmptyDir: true
  # -- Size limit for the empty directory (only applicable if useEmptyDir is true)
  sizeLimit: 8Gi
  # -- PVC name for /dev/shm (overrides useEmptyDir if set)
  pvcName: ""
